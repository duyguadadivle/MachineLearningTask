{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc14aaa4-a751-4764-9584-6bec56485af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to create\n",
    "# Image Classifier using CNN\n",
    "\n",
    "# Importing the required libraries\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b594b01c-905e-4afc-900e-264af5c0378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Setting up the env'''\n",
    "\n",
    "TRAIN_DIR = 'Cats_vs_Dogs / train'\n",
    "TEST_DIR = 'Cats_vs_Dogs / test1'\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8868f746-b3ed-4ec7-b941-5b914f2a4dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Setting up the model which will help with tensorflow models'''\n",
    "MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '6conv-basic')\n",
    "\n",
    "'''Labelling the dataset'''\n",
    "def label_img(img):\n",
    "\tword_label = img.split('.')[-3]\n",
    "\t# DIY One hot encoder\n",
    "\tif word_label == 'cat': return [1, 0]\n",
    "\telif word_label == 'dog': return [0, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23e53b16-e348-49dd-ba0b-c3458e0e3c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating the training data'''\n",
    "def create_train_data():\n",
    "\t# Creating an empty list where we should store the training data\n",
    "\t# after a little preprocessing of the data\n",
    "\ttraining_data = []\n",
    "\n",
    "\t# tqdm is only used for interactive loading\n",
    "\t# loading the training data\n",
    "\tfor img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "\n",
    "\t\t# labeling the images\n",
    "\t\tlabel = label_img(img)\n",
    "\n",
    "\t\tpath = os.path.join(TRAIN_DIR, img)\n",
    "\n",
    "\t\t# loading the image from the path and then converting them into\n",
    "\t\t# grayscale for easier covnet prob\n",
    "\t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\t\t# resizing the image for processing them in the covnet\n",
    "\t\timg = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "\t\t# final step-forming the training data list with numpy array of the images\n",
    "\t\ttraining_data.append([np.array(img), np.array(label)])\n",
    "\n",
    "\t# shuffling of the training data to preserve the random state of our data\n",
    "\tshuffle(training_data)\n",
    "\n",
    "\t# saving our trained data for further uses if required\n",
    "\tnp.save('train_data.npy', training_data)\n",
    "\treturn training_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f97b4d0-3611-440d-b23c-e09e3d71ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Processing the given test data'''\n",
    "# Almost same as processing the training data but\n",
    "# we dont have to label it.\n",
    "def process_test_data():\n",
    "\ttesting_data = []\n",
    "\tfor img in tqdm(os.listdir(TEST_DIR)):\n",
    "\t\tpath = os.path.join(TEST_DIR, img)\n",
    "\t\timg_num = img.split('.')[0]\n",
    "\t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\t\timg = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\t\ttesting_data.append([np.array(img), img_num])\n",
    "\t\t\n",
    "\tshuffle(testing_data)\n",
    "\tnp.save('test_data.npy', testing_data)\n",
    "\treturn testing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6089a5d-3fd4-43ce-bf21-75d76c0318f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Cats_vs_Dogs / train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22448/3011740338.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m'''Running the training and the testing in the dataset for our model'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_data.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22448/192937828.py\u001b[0m in \u001b[0;36mcreate_train_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# tqdm is only used for interactive loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# loading the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[1;31m# labeling the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Cats_vs_Dogs / train'"
     ]
    }
   ],
   "source": [
    "\n",
    "'''Running the training and the testing in the dataset for our model'''\n",
    "train_data = create_train_data()\n",
    "test_data = process_test_data()\n",
    "\n",
    "# train_data = np.load('train_data.npy')\n",
    "# test_data = np.load('test_data.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbf82776-baf4-45d8-8980-61e8455bc14d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tflearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22448/1341317284.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m'''Creating the neural network using tensorflow'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Importing the required libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_pool_2d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfully_connected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tflearn'"
     ]
    }
   ],
   "source": [
    "'''Creating the neural network using tensorflow'''\n",
    "# Importing the required libraries\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc1f4a88-8084-4fc5-990a-c6d04a310660",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'reset_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22448/4046318476.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mconvnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconvnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "convnet = input_data(shape =[None, IMG_SIZE, IMG_SIZE, 1], name ='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation ='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation ='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation ='softmax')\n",
    "convnet = regression(convnet, optimizer ='adam', learning_rate = LR,\n",
    "\tloss ='categorical_crossentropy', name ='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir ='log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82f3f87e-88e2-4dda-8efc-def1de641b96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22448/2786073407.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Splitting the testing data and training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;34m'''Setting up the features and labels'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Splitting the testing data and training data\n",
    "train = train_data[:-500]\n",
    "test = train_data[-500:]\n",
    "\n",
    "'''Setting up the features and labels'''\n",
    "# X-Features & Y-Labels\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "Y = [i[1] for i in train]\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "test_y = [i[1] for i in test]\n",
    "\n",
    "'''Fitting the data into our model'''\n",
    "# epoch = 5 taken\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch = 5,\n",
    "\tvalidation_set =({'input': test_x}, {'targets': test_y}),\n",
    "\tsnapshot_step = 500, show_metric = True, run_id = MODEL_NAME)\n",
    "model.save(MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ca99a06-13b1-4f2b-9476-1a6c8ed969ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22448/52099153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# test_data = process_test_data()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# if you already have some saved:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_data.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_data.npy'"
     ]
    }
   ],
   "source": [
    "'''Testing the data'''\n",
    "import matplotlib.pyplot as plt\n",
    "# if you need to create the data:\n",
    "# test_data = process_test_data()\n",
    "# if you already have some saved:\n",
    "test_data = np.load('test_data.npy')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for num, data in enumerate(test_data[:20]):\n",
    "\t# cat: [1, 0]\n",
    "\t# dog: [0, 1]\n",
    "\t\n",
    "\timg_num = data[1]\n",
    "\timg_data = data[0]\n",
    "\t\n",
    "\ty = fig.add_subplot(4, 5, num + 1)\n",
    "\torig = img_data\n",
    "\tdata = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "\t# model_out = model.predict([data])[0]\n",
    "\tmodel_out = model.predict([data])[0]\n",
    "\t\n",
    "\tif np.argmax(model_out) == 1: str_label ='Dog'\n",
    "\telse: str_label ='Cat'\n",
    "\t\t\n",
    "\ty.imshow(orig, cmap ='gray')\n",
    "\tplt.title(str_label)\n",
    "\ty.axes.get_xaxis().set_visible(False)\n",
    "\ty.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92040a09-cfab-4812-92d7-8cd7e669dd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651463f-1792-407d-a846-b44ce83ca4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d9fa34-82a8-44e0-a12f-fda76c1d31c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
