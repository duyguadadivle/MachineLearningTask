{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76e2148-91df-4902-9acf-bc3d161d45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow . keras.preprocessing import sequence \n",
    "from numpy import array \n",
    "import logging \n",
    "logging.getLogger ('tensorflow').disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "916ae90a-e060-460f-980f-13db2d991eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch \" IMDB Movie Review \" data , constraining our reviews to \n",
    "# the 10000 most commonly used words \n",
    "vocab_size = 10000 \n",
    "(x_train, y_train), (x_test, y_test ) = tf.keras.datasets.imdb.load_data (num_words = vocab_size) \n",
    "\n",
    "# Map for readable classnames \n",
    "class_names = [\"Negative\" ,\"Positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cc76fd-67fa-4546-9488-def4effed9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index from the dataset \n",
    "word_index = tf.keras.datasets.imdb.get_word_index () \n",
    "\n",
    "# Ensure that \" special \" words are mapped into human readable terms \n",
    "word_index = {k: (v + 3) for k , v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0 \n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNKNOWN>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3 \n",
    "\n",
    "# Perform reverse word Lookup and make it callable \n",
    "reverse_word_index = dict([(value, key) for(key, value) in word_index.items()]) \n",
    "def decode_review (text): \n",
    "    return ' '.join ([reverse_word_index.get (i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db49706b-c5cf-41da-ae0c-60d74fb1e914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 2494\n",
      "Minimum review length: 7\n",
      "Mean review length: 234.75892\n",
      "Machine readable Review\n",
      "Review Text :[1, 13, 219, 14, 33, 4, 2, 22, 1413, 12, 16, 373, 175, 2711, 1115, 1026, 430, 939, 16, 23, 2444, 25, 43, 697, 89, 12, 16, 170, 8, 130, 262, 19, 32, 4, 665, 7, 4, 2, 322, 5, 4, 1520, 7, 4, 86, 250, 10, 10, 4, 249, 173, 16, 4, 3891, 6, 19, 4, 167, 564, 5, 564, 1325, 36, 805, 8, 216, 638, 17, 2, 21, 25, 100, 376, 507, 4, 2110, 15, 79, 125, 23, 567, 13, 2134, 233, 36, 4852, 2, 5, 81, 1672, 10, 10, 92, 437, 129, 58, 13, 69, 8, 401, 61, 1432, 39, 1286, 46, 7, 12]\n",
      "Review Sentiment :0\n",
      "Human Readable Review\n",
      "Review Text: <START> i saw this at the <UNKNOWN> film festival it was awful every clichéd violent rich boy fantasy was on display you just knew how it was going to end especially with all the shots of the <UNKNOWN> wife and the rape of the first girl br br the worst part was the q a with the director writer and writer producer they tried to come across as <UNKNOWN> but you could tell they're the types that get off on violence i bet anything they frequent <UNKNOWN> and do drugs br br don't waste your time i had to keep my boyfriend from walking out of it\n",
      "Review Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# Concatonate test and training datasets \n",
    "allreviews = np.concatenate (( x_train, x_test ), axis = 0 ) \n",
    "\n",
    "# Review Lengths across test and training whole datasets \n",
    "print(\"Maximum review length: {}\".format(len(max((allreviews), key = len)))) \n",
    "print(\"Minimum review length: {}\".format(len(min((allreviews), key = len)))) \n",
    "result = [len(x) for x in allreviews] \n",
    "print(\"Mean review length: {}\".format(np.mean(result))) \n",
    "\n",
    "# Print a review and it's class as stored in the dataset . Replace the number \n",
    "# to select a different review . print ( \" \" ) \n",
    "print(\"Machine readable Review\") \n",
    "print(\"Review Text :\" + str (x_train [60])) \n",
    "print(\"Review Sentiment :\" + str (y_train[60])) \n",
    "\n",
    "# Print a review and it's class in human readable format . Replace the number \n",
    "# to select a different review . print ( \" \" ) \n",
    "print(\"Human Readable Review\") \n",
    "print(\"Review Text: \" + decode_review (x_train [60])) \n",
    "print(\"Review Sentiment: \" + class_names [y_train[60]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183dee38-ac1f-4675-b73f-2388ded1a1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Training Review Data: (25000, 500)\n",
      "Shape Training Class Data: (25000,)\n",
      "Shape Test Review Data: (25000, 500)\n",
      "Shape Test Class Data: (25000,)\n",
      "Human Readable Review Text (post padding): <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> i saw this at the <UNKNOWN> film festival it was awful every clichéd violent rich boy fantasy was on display you just knew how it was going to end especially with all the shots of the <UNKNOWN> wife and the rape of the first girl br br the worst part was the q a with the director writer and writer producer they tried to come across as <UNKNOWN> but you could tell they're the types that get off on violence i bet anything they frequent <UNKNOWN> and do drugs br br don't waste your time i had to keep my boyfriend from walking out of it\n"
     ]
    }
   ],
   "source": [
    "# The Length of reviews \n",
    "review_length = 500 \n",
    "\n",
    "# Padding / truncated our reviews \n",
    "x_train = sequence.pad_sequences(x_train, maxlen = review_length) \n",
    "x_test = sequence.pad_sequences(x_test, maxlen = review_length) \n",
    "\n",
    "# Check the size of our datasets. Review data for both test and training should \n",
    "# contain 25000 reviews of 500 integers. Class data should contain 25000 values , \n",
    "# one for each review . Class values are 0 or 1 , indicating a negative \n",
    "# or positive review . \n",
    "print(\"Shape Training Review Data: \" + str(x_train.shape)) \n",
    "print(\"Shape Training Class Data: \" + str(y_train.shape)) \n",
    "print(\"Shape Test Review Data: \" + str(x_test.shape))\n",
    "print(\"Shape Test Class Data: \"  + str(y_test.shape)) \n",
    "# Note padding is added to start of review , not the end print (\"\") \n",
    "print(\"Human Readable Review Text (post padding): \" + decode_review ( x_train [60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67a69c45-ff74-4181-bbe0-aa05c5a412ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 32)           320000    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 500, 32)           0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500, 32)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,353\n",
      "Trainable params: 328,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We begin by defining the a empty stack . We'll use this for building our \n",
    "# network , later by Layer. \n",
    "model = tf.keras.models.Sequential() \n",
    "\n",
    "# The Embedding Layer provides a spatial mapping ( or Word Embedding ) of all the \n",
    "# individual words in our training set . Words close to one another share context \n",
    "# and or meaning. This spatial mapping is learning during the training process.\n",
    "model.add(\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim = vocab_size, # The size of our vocabulary \n",
    "        output_dim = 32, # Dimensions to which each words shall be mapped \n",
    "        input_length = review_length # Length of input sequences \n",
    "    )\n",
    ")\n",
    "# Dropout Layers fight overfitting and forces the model to learn multiple \n",
    "# representations of the same data by randomly disabling neurons in the \n",
    "# Learning phase. \n",
    "model.add( \n",
    "    tf.keras.layers.Dropout(\n",
    "        rate = 0.25 # Randomly disable 25 % of neurons\n",
    "    )\n",
    ")\n",
    "# Dropout Layers fight overfitting and forces the model to learn multiple \n",
    "# representations of the same data by randomly disabling neurons in the \n",
    "# Learning phase. \n",
    "model.add(\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate = 0.25 # Randomly disable 25 % of neurons \n",
    "    ) \n",
    ") \n",
    "# We are using a fast version of LSTM whih is optimised for GPUs . This Layer \n",
    "# Looks at the sequence of words in the review , along with their word embeddings\n",
    "# and uses both of these to determine to sentiment of a given review .\n",
    "model.add(\n",
    "    tf.keras.layers.LSTM(\n",
    "        units = 32 # 32 LSTM units in this layer \n",
    "     ) \n",
    ") \n",
    "# Add a second dropout layer with the same aim as the first.\n",
    "model.add(\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate = 0.25 # Randomly disable 25 % of neurons \n",
    "    ) \n",
    ")\n",
    "\n",
    "# ALL LSTM units are connected to a single node in the dense Layer . A sigmoid \n",
    "# activation function determines the output from this node - a value \n",
    "# between 0 and 1. Closer to indicates a negative review . closer to 1 \n",
    "# indicates a positive review.\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units = 1, # Single unit \n",
    "        activation = 'sigmoid' # Sigmoid activation function(output from 0 to 1)\n",
    "    )\n",
    ")\n",
    "# Compile the model \n",
    "model.compile( \n",
    "    loss = tf.keras.losses.binary_crossentropy, # Loss function \n",
    "    optimizer = tf.keras.optimizers.Adam(), # optimiser function \n",
    "    metrics = ['accuracy']) # reporting metric \n",
    "# Display a summary of the models structure \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc45518-9e55-4804-b22f-293cc5c1d825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "79/79 [==============================] - 160s 2s/step - loss: 0.6095 - accuracy: 0.6638 - val_loss: 0.4245 - val_accuracy: 0.8332\n",
      "Epoch 2/3\n",
      "79/79 [==============================] - 150s 2s/step - loss: 0.3360 - accuracy: 0.8687 - val_loss: 0.3026 - val_accuracy: 0.8812\n",
      "Epoch 3/3\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.2441 - accuracy: 0.9085 - val_loss: 0.2941 - val_accuracy: 0.8808\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM on the training data \n",
    "history = model.fit ( \n",
    "    # Training data : features ( review ) and classes ( positive or negative ) \n",
    "    x_train , y_train, \n",
    "    # Number of samples to work through before updating the \n",
    "    # internal model parameters via back propagation. The \n",
    "    # higher the batch , the more memory you need.\n",
    "    \n",
    "    batch_size = 256, \n",
    "    # An epoch is an iteration over the entire training data. \n",
    "    epochs = 3 ,# The model will set apart his fraction of the training\n",
    "    # data , will not train on it , and will evaluate the loss \n",
    "    # and any model metrics on this data at the end of \n",
    "    # each epoch.\n",
    "    validation_split = 0.2,\n",
    "    verbose = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f12d3358-39f3-4969-8273-c779fb564b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      0.93      0.88     12500\n",
      "    Positive       0.92      0.81      0.86     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Model Predictions for test data \n",
    "from sklearn.metrics import classification_report \n",
    "predictions = (model.predict (x_test) > 0.5).astype (\"int32\") \n",
    "print (classification_report (y_test, predictions , target_names = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b174fa8d-7fd4-4ec2-940a-9540a5fe5e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
